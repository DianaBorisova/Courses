{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Необходимо знать, что интересует пользователей в связи с оскаром: до него, во время и после. Для этого вам предлагается проанализировать логи поисковых запросов. Далее предложите несколько вариантов классификации этих запросов.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords \n",
    "from pymystem3 import Mystem\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Считаем логи поисковых запросов. Посмотрим на данные и время, за которое они собраны.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_query</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neityfz говядина как консервы</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>водокаал алексин</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>настя шевцова и гуф</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ул барсова 7 сочи</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>доп соглашение к срочному трудовому договору о...</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        normal_query             datetime\n",
       "0                      neityfz говядина как консервы  2019-01-23 09:39:25\n",
       "1                                   водокаал алексин  2019-01-23 09:39:25\n",
       "2                                настя шевцова и гуф  2019-01-23 09:39:25\n",
       "3                                  ул барсова 7 сочи  2019-01-23 09:39:25\n",
       "4  доп соглашение к срочному трудовому договору о...  2019-01-23 09:39:25"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscar = pd.read_csv('oscar.csv', delimiter='\\t')\n",
    "oscar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-22 00:00:00 2019-02-28 23:59:58\n"
     ]
    }
   ],
   "source": [
    "print(min(oscar['datetime']), max(oscar['datetime']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Присвоим переменным start_dttm и end_dttm время начала и окончания премии Оскар. Добавим новый столбец, отображающий когда был сделан запрос: до премии, во время нее или после.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_query</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neityfz говядина как консервы</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>водокаал алексин</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>настя шевцова и гуф</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ул барсова 7 сочи</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>доп соглашение к срочному трудовому договору о...</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        normal_query             datetime  \\\n",
       "0                      neityfz говядина как консервы  2019-01-23 09:39:25   \n",
       "1                                   водокаал алексин  2019-01-23 09:39:25   \n",
       "2                                настя шевцова и гуф  2019-01-23 09:39:25   \n",
       "3                                  ул барсова 7 сочи  2019-01-23 09:39:25   \n",
       "4  доп соглашение к срочному трудовому договору о...  2019-01-23 09:39:25   \n",
       "\n",
       "  time_period  \n",
       "0      before  \n",
       "1      before  \n",
       "2      before  \n",
       "3      before  \n",
       "4      before  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_dttm = '2019-01-25 04:00:00'\n",
    "end_dttm = '2019-01-25 07:30:00'\n",
    "\n",
    "def period_query (date):\n",
    "    if date < start_dttm:\n",
    "        return 'before'\n",
    "    elif date <= end_dttm:\n",
    "        return 'during'\n",
    "    else:\n",
    "        return 'after'\n",
    "    \n",
    "oscar['time_period'] = oscar['datetime'].apply(period_query)\n",
    "oscar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перед классификацией необходимо провести предобработку. Для этого приведем запросы к нижнему регистру и разобьем их на токены. Также удалим стоп слова, пунктуацию и приведем слова к начальной форме (нормализуем).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian')) \n",
    "punctuation_set = set(punctuation)\n",
    "mystem = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 23s, sys: 6min 30s, total: 31min 54s\n",
      "Wall time: 2h 20min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def preprocess(query):\n",
    "    tokenize = mystem.lemmatize(str(query).strip().lower())\n",
    "    tokenize.pop()\n",
    "    clean_queries = [\n",
    "        word for word in tokenize if word not in stop_words and word not in punctuation_set\n",
    "    ]\n",
    "    return \"\".join(clean_queries)\n",
    "\n",
    "oscar['normalize_word'] = oscar['normal_query'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_query</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_period</th>\n",
       "      <th>normalize_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neityfz говядина как консервы</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>neityfz говядина  консервы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>водокаал алексин</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>водокаал алексин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>настя шевцова и гуф</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>настя шевцова  гуф</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ул барсова 7 сочи</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>ул барсов 7 сочи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>доп соглашение к срочному трудовому договору о...</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>допы соглашение  срочный трудовой договор  пер...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>carku e power 21</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>carku e power 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ловим налима осенью видео</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>ловить налим осень видео</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>росгосстрах</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>росгосстрах</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>конвертер валют</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>конвертер валюта</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>карточка на ручку номера не беспокоить купить ...</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>карточка  ручка номер  беспокоить купить  крас...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        normal_query             datetime  \\\n",
       "0                      neityfz говядина как консервы  2019-01-23 09:39:25   \n",
       "1                                   водокаал алексин  2019-01-23 09:39:25   \n",
       "2                                настя шевцова и гуф  2019-01-23 09:39:25   \n",
       "3                                  ул барсова 7 сочи  2019-01-23 09:39:25   \n",
       "4  доп соглашение к срочному трудовому договору о...  2019-01-23 09:39:25   \n",
       "5                                   carku e power 21  2019-01-23 09:39:25   \n",
       "6                          ловим налима осенью видео  2019-01-23 09:39:25   \n",
       "7                                        росгосстрах  2019-01-23 09:39:25   \n",
       "8                                    конвертер валют  2019-01-23 09:39:25   \n",
       "9  карточка на ручку номера не беспокоить купить ...  2019-01-23 09:39:25   \n",
       "\n",
       "  time_period                                     normalize_word  \n",
       "0      before                         neityfz говядина  консервы  \n",
       "1      before                                   водокаал алексин  \n",
       "2      before                                 настя шевцова  гуф  \n",
       "3      before                                   ул барсов 7 сочи  \n",
       "4      before  допы соглашение  срочный трудовой договор  пер...  \n",
       "5      before                                   carku e power 21  \n",
       "6      before                           ловить налим осень видео  \n",
       "7      before                                        росгосстрах  \n",
       "8      before                                   конвертер валюта  \n",
       "9      before  карточка  ручка номер  беспокоить купить  крас...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscar.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oscar.to_csv('norm_oscar.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_query</th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_period</th>\n",
       "      <th>normalize_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neityfz говядина как консервы</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>neityfz говядина  консервы</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>водокаал алексин</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>водокаал алексин</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>настя шевцова и гуф</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>настя шевцова  гуф</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ул барсова 7 сочи</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>ул барсов 7 сочи</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>доп соглашение к срочному трудовому договору о...</td>\n",
       "      <td>2019-01-23 09:39:25</td>\n",
       "      <td>before</td>\n",
       "      <td>допы соглашение  срочный трудовой договор  пер...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        normal_query             datetime  \\\n",
       "0                      neityfz говядина как консервы  2019-01-23 09:39:25   \n",
       "1                                   водокаал алексин  2019-01-23 09:39:25   \n",
       "2                                настя шевцова и гуф  2019-01-23 09:39:25   \n",
       "3                                  ул барсова 7 сочи  2019-01-23 09:39:25   \n",
       "4  доп соглашение к срочному трудовому договору о...  2019-01-23 09:39:25   \n",
       "\n",
       "  time_period                                     normalize_word  \n",
       "0      before                         neityfz говядина  консервы  \n",
       "1      before                                   водокаал алексин  \n",
       "2      before                                 настя шевцова  гуф  \n",
       "3      before                                   ул барсов 7 сочи  \n",
       "4      before  допы соглашение  срочный трудовой договор  пер...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oscar = pd.read_csv('norm_oscar.csv')\n",
    "oscar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разделим датасет на запросы: до Оскара, во время и после него.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "before_oscar = oscar[oscar['time_period'] =='before']['normalize_word'].dropna()\n",
    "during_oscar = oscar[oscar['time_period'] =='during']['normalize_word'].dropna()\n",
    "after_oscar = oscar[oscar['time_period'] =='after']['normalize_word'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим функцию, которая делает tf-idf преобразование. Оно позволяет учитывать не только наличие слова в запросе, но и его значимость.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=10) #токены, имеющие частотноть ниже 10 не будут учитываться\n",
    "\n",
    "def tf_idf(data):\n",
    "    vec_tfidf = tfidf.fit_transform(data)\n",
    "    return pd.DataFrame(data=vec_tfidf.toarray(), columns=tfidf.get_feature_names(), index=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что интересует пользователей до Оскара. Выберем 50 000 рандомных запросов и кластеризуем их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample \n",
    "\n",
    "sample1 = sample(list(before_oscar), 50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Воспользуемся методом k-средних для кластеризации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=5, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Ищем группы.\n",
    "k_means = KMeans(n_clusters=20,\n",
    "                init='k-means++',\n",
    "                n_init=10,\n",
    "                max_iter=300,\n",
    "                tol=0.0001,\n",
    "                n_jobs=5)\n",
    "\n",
    "k_means.fit(tf_idf(sample1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ключевые слова выводим в группы для анализа\n",
    "dct = {}\n",
    "for key, label in zip(sample1, k_means.labels_):\n",
    "    dct[label] = dct.get(label, []) + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "тушь фаберлик ваш оскар\n",
      "1\n",
      "оскар синеть\n",
      "1\n",
      "список номинант  оскар 2019\n",
      "1\n",
      "статуэтка оскар купить омск\n",
      "1\n",
      "  телевизионный канал  россия  посмотреть награждение премия оскар\n",
      "1\n",
      "оскар 2019\n",
      "1\n",
      "оскар 2019\n",
      "1\n",
      "фоскарнет\n",
      "1\n",
      "тес роскар\n",
      "1\n",
      "оскар ремез  бабушка яга\n",
      "17\n",
      "фильм  оскар 2019\n"
     ]
    }
   ],
   "source": [
    "for x in range(20):\n",
    "    for line in dct[x]:\n",
    "        if 'оскар' in line or 'oscar' in line:\n",
    "            print(x)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создадим Sample 2 и посмотрим насколько сильные различия в кластеризации разных выборок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample2 = sample(list(before_oscar), 50000)\n",
    "del before_oscar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=100, n_init=20, n_jobs=5, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_means = KMeans(n_clusters=100,\n",
    "                init='k-means++',\n",
    "                n_init=20,\n",
    "                max_iter=300,\n",
    "                n_jobs=5)\n",
    "\n",
    "k_means.fit(tf_idf(sample2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for key, label in zip(sample2, k_means.labels_):\n",
    "    dct[label] = dct.get(label, []) + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "номинанта  оскар\n",
      "35\n",
      "фильм награждать премия оскар  хороший\n",
      "44\n",
      "слушать оскар    \n",
      "70\n",
      "оскар     скачать бесплатно mp3\n",
      "86\n",
      "оскар 2019 номинанта\n",
      "86\n",
      "номинанта  оскар 2019\n",
      "86\n",
      "номинанта  оскар 2019 список\n"
     ]
    }
   ],
   "source": [
    "for x in range(100):\n",
    "    for line in dct[x]:\n",
    "        if 'оскар' in line or 'oscar' in line:\n",
    "            print(x)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несмотря на то, что имеются различия в двух выборках, по кластерам обеих выборок можно сделать вывод. Больше всего пользователей до начала премии Оскар интересует список номинантов и возможность посмотреть трансляцию премии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь посмотрим, что интересует пользователей во время Оскара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57805"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "during_oscar = oscar[oscar['time_period'] =='during']['normalize_word'].dropna()\n",
    "len(during_oscar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6ae21e7d9875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 n_jobs=5)\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mk_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_idf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduring_oscar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 896\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    361\u001b[0m                                    \u001b[0;31m# Change seed to ensure variety\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                                    random_state=seed)\n\u001b[0;32m--> 363\u001b[0;31m             for seed in seeds)\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0;31m# Get results with the lowest inertia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Прерывала после повторного запуска -- долгоооо\n",
    "k_means = KMeans(n_clusters=10,\n",
    "                init='k-means++',\n",
    "                n_init=20,\n",
    "                max_iter=300,\n",
    "                n_jobs=5)\n",
    "\n",
    "k_means.fit(tf_idf(during_oscar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for key, label in zip(during_oscar, k_means.labels_):\n",
    "    dct[label] = dct.get(label, []) + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "оскар\n",
      "4\n",
      "премия оскар\n",
      "4\n",
      "читать мотивационный книга  книга оскар уалд\n",
      "4\n",
      "патриотизм религия бешеный оскар уайльд  английский\n",
      "4\n",
      "греф герман оскарович биография\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    for line in dct[x]:\n",
    "        if 'оскар' in line or 'oscar' in line:\n",
    "            print(x)\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время премии Оскар пользователей интересует премия Оскар!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что интересует пользователей после Оскара."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample3 = sample(list(after_oscar), 30000)\n",
    "\n",
    "k_means = KMeans(n_clusters=10,\n",
    "                init='k-means++',\n",
    "                n_init=20,\n",
    "                max_iter=300,\n",
    "                n_jobs=5)\n",
    "\n",
    "k_means.fit(tf_idf(sample3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dct = {}\n",
    "for key, label in zip(sample3, k_means.labels_):\n",
    "    dct[label] = dct.get(label, []) + [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    for line in dct[x]:\n",
    "        if 'оскар' in line or 'oscar' in line:\n",
    "            print(x)\n",
    "            print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
